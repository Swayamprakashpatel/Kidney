{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kidney_Stone.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYVJQKvGGfXBs8YMN16DZd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swayamprakashpatel/Kidney/blob/main/Kidney_Stone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWybAXBUXRJA",
        "cellView": "form"
      },
      "source": [
        "#@title Train Model\n",
        "%%capture\n",
        "import tensorflow as tf\n",
        "#import tensorflowjs as tfjs\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import io \n",
        "\n",
        "url = 'https://github.com/Swayamprakashpatel/Kidney/raw/main/Data_File.xlsx'\n",
        "Data_File = pd.read_excel(url)\n",
        "\n",
        "#Data_File = pd.read_excel('/content/Data_File.xlsx') \n",
        "#print(Data_File)\n",
        "#print (Data_File.shape)\n",
        "\n",
        "# Input and output defining\n",
        "\n",
        "Data_Set = Data_File.values\n",
        "Data_Set = Data_Set [:,0:22]\n",
        "X1 = Data_Set[:,0:21]\n",
        "Y1 = Data_Set [:,21:22]\n",
        "#print (Data_Set, Data_Set.shape)\n",
        "#print (X1, X1.shape)\n",
        "#print(Y1, Y1.shape)\n",
        "\n",
        "# onehot encoding of cateogrial data in input data\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(), [0,1,2,3,4,5,6,7,8,9,10])] , remainder='passthrough')\n",
        "X1 = np.array(ct.fit_transform(X1))\n",
        "#print(X1)\n",
        "#print(X1.shape)\n",
        "#print(X1.dtype)\n",
        "\n",
        "# Scaling of Input Data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X1)\n",
        "print(X1, X1.shape, X1.dtype)\n",
        "\n",
        "# Output data one hot encoding\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(Y1)\n",
        "OneHotEncoder(handle_unknown='ignore')\n",
        "enc.categories_\n",
        "Y = enc.transform(Y1).toarray()\n",
        "#print(Y, Y.shape, Y.dtype)\n",
        "\n",
        "#spliting data in test, train and validation batches\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X, Y, test_size=0.3,random_state = 42 )\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5, random_state= 42)\n",
        "\n",
        "#ANN MODEL\n",
        "X_train = np.asarray(X_train).astype(np.int64)\n",
        "X_val = np.asarray(X_val).astype(np.int64)\n",
        "X_test = np.asarray(X_test).astype(np.int64)\n",
        "Y_train = np.asarray(Y_train).astype(np.int64)\n",
        "Y_val = np.asarray(Y_val).astype(np.int64)\n",
        "Y_test = np.asarray(Y_test).astype(np.int64)\n",
        " \n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "filepath = '/content/drive/MyDrive/Model_DE/Kindney_Model.hdf5'\n",
        " \n",
        "checkpoint = [tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', save_best_only=True, Save_weights_only = False, verbose = 1), \n",
        "              tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=25, verbose =1), [tensorboard_callback]]\n",
        "\n",
        "output_nodes = Y.shape[1]\n",
        "print(output_nodes)\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(512, activation='relu', input_shape=(38,)),\n",
        "                             tf.keras.layers.Dense(512, activation='relu'),\n",
        "                             tf.keras.layers.Dense(512, activation='relu'),\n",
        "                             tf.keras.layers.Dense(output_nodes, activation= 'softmax')])\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss=tf.keras.losses.BinaryCrossentropy(from_logits = False), metrics=['accuracy'])\n",
        "hist = model.fit(X_train, Y_train, epochs= 2000, callbacks=[checkpoint],validation_data=(X_val, Y_val), batch_size= 2000)\n",
        "model.evaluate(X_test, Y_test)\n",
        " \n",
        "Y_train_predict = np.round(model.predict(X_train))\n",
        "Y_train_l = tf.argmax(Y_train, axis = 1)\n",
        "Y_train_predict_l = tf.argmax(Y_train_predict, axis =1)\n",
        "import sklearn.metrics as skm\n",
        "cm = skm.multilabel_confusion_matrix(Y_train_l, Y_train_predict_l)\n",
        "print(cm)\n",
        "print( skm.classification_report(Y_train_l, Y_train_predict_l))\n",
        " \n",
        "train_acc = max(hist.history['accuracy'])\n",
        "val_acc = max(hist.history['val_accuracy'])\n",
        "train_loss = min(hist.history['loss'])\n",
        "val_loss = min(hist.history['val_loss'])\n",
        "print('Training Accuracy is')\n",
        "print(train_acc)\n",
        "print('Validation Accuracy is')\n",
        "print(val_acc)\n",
        "print('Training loss is')\n",
        "print(train_loss)\n",
        "print('Validation loss is')\n",
        "print(val_loss)\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SyQ0lEWyJ5I",
        "cellView": "form"
      },
      "source": [
        "#@title Input Patient Details\n",
        "Gender = \"Male\" #@param [\"Male\", \"Female\"]\n",
        "Family_History = \"YES\" #@param [\"YES\", \"NO\"]\n",
        "Recurrent = \"YES\" #@param [\"YES\", \"NO\"]\n",
        "Food_Habit = \"Vegetarian\" #@param [\"Vegetarian\", \"Non-Vegetarian\"]\n",
        "Water = \"RO WATER\" #@param [\"RO WATER\", \"FILTERED WATER\", \"TAP-WATER\"]\n",
        "Salt_Intake = \"MODERATE\" #@param [\"MODERATE\", \"LOW\", \"HIGH\"]\n",
        "rs1126616_SPP1 = \"CC\" #@param [\"CC\", \"CT\", \"TT\"]\n",
        "rs4293393_UMOD = \"AA\" #@param [\"AA\", \"AG\", \"GG\"]\n",
        "rs1801725_CASR = \"GG\" #@param [\"GG\", \"GT\", \"TT\"]\n",
        "rs1042636_CASR = \"AA\" #@param [\"AA\", \"AG\", \"GG\"]\n",
        "rs142287570_GCM2 = \"GG\" #@param [\"GG\", \"TG\"]\n",
        "S_CREATININE_mg_per_dl = 0 #@param {type:\"number\"}\n",
        "S_CALCIUM_mg_per_dl = 0 #@param {type:\"number\"}\n",
        "PTH_pg_ml = 0 #@param {type:\"number\"}\n",
        "U_Phosphorus_mg_day = 0 #@param {type:\"number\"}\n",
        "U_Citrate_mg_day = 0 #@param {type:\"number\"}\n",
        "U_Oxalate_mg_day = 0 #@param {type:\"number\"}\n",
        "U_Uric_Acid_mg_day = 0 #@param {type:\"number\"}\n",
        "U_Calcium_mg_day = 0 #@param {type:\"number\"}\n",
        "U_Magnesium_mg_day = 0 #@param {type:\"number\"}\n",
        "U_Creatinine_mg_day = 0 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "A = pd.DataFrame([Gender])\n",
        "B = pd.DataFrame([Family_History])\n",
        "C = pd.DataFrame([Recurrent])\n",
        "D = pd.DataFrame([Food_Habit])\n",
        "E = pd.DataFrame([Water])\n",
        "F = pd.DataFrame([Salt_Intake])\n",
        "G = pd.DataFrame([rs1126616_SPP1])\n",
        "H = pd.DataFrame([rs4293393_UMOD])\n",
        "I = pd.DataFrame([rs1801725_CASR])\n",
        "J = pd.DataFrame([rs1042636_CASR])\n",
        "K = pd.DataFrame([rs142287570_GCM2])\n",
        "L = pd.DataFrame([S_CREATININE_mg_per_dl])\n",
        "M = pd.DataFrame([S_CALCIUM_mg_per_dl])\n",
        "N = pd.DataFrame([PTH_pg_ml])\n",
        "O = pd.DataFrame([U_Phosphorus_mg_day])\n",
        "P = pd.DataFrame([U_Citrate_mg_day])\n",
        "Q = pd.DataFrame([U_Oxalate_mg_day])\n",
        "R = pd.DataFrame([U_Uric_Acid_mg_day])\n",
        "S = pd.DataFrame([U_Calcium_mg_day])\n",
        "T = pd.DataFrame([U_Magnesium_mg_day])\n",
        "U = pd.DataFrame([U_Creatinine_mg_day])\n",
        "\n",
        "Input1 = np.concatenate((A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U), axis=1)\n",
        "Input1 = pd.DataFrame(np.array(Input1))\n",
        "\n",
        "Dummy = pd.DataFrame(np.array([['Female','NO','NO','Vegetarian','RO WATER','LOW','CC','AA','GG','AA','GG',2.6,11.19,299.3,1127.1,610.8,77.9,1301.3,414.8,204.24,1985.7],\n",
        "                               ['Male','YES','YES','Non-Vegetarian','FILTERED WATER','MODERATE','CT','AG','GT','AG','TG',0.55,9.93,51.3,246,323.4,32.6,396,24,57.12,692.64],\n",
        "                               ['Female','NO','NO','Vegetarian','TAP-WATER','HIGH','TT','GG','TT','GG','TG',0.55,9.93,51.3,246,323.4,32.6,396,24,57.12,692.64]]))\n",
        "Input = pd.DataFrame.append(Input1, Dummy)\n",
        "Input = pd.DataFrame(Input)\n",
        "Input = Input.iloc[:, 0:22]\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(), [0,1,2,3,4,5,6,7,8,9,10])] , remainder='passthrough')\n",
        "P1 = np.array(ct.fit_transform(Input))\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "P2 = scaler.fit_transform(P1)\n",
        "P2 = pd.DataFrame(P2)\n",
        "\n",
        "Pred_Data = P2.iloc[0:1,:]\n",
        "Prediction = model.predict(Pred_Data)\n",
        "Prediction = np.round(Prediction)\n",
        "\n",
        "Y1 = np.array([['Possibally Negative'], ['Possibally Possitive']])\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(Y1)\n",
        "OneHotEncoder(handle_unknown='ignore')\n",
        "enc.categories_\n",
        "Y = enc.transform(Y1).toarray()\n",
        "Prediction = enc.inverse_transform(Prediction)\n"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa6L9j_LOgZq",
        "outputId": "26f40b83-e1c2-468a-b8d5-04e47d3cebfc"
      },
      "source": [
        "print (Prediction)"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Possibally Possitive']]\n"
          ]
        }
      ]
    }
  ]
}